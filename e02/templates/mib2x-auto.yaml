apiVersion: argoproj.io/v1alpha1
kind: ClusterWorkflowTemplate
metadata:
  name: e02mib2x-auto
  annotations:
    workflows.argoproj.io/title: ePSIC mib automatic conversion
    workflows.argoproj.io/description: |
      Convert MIB file to hdf5/hspy files
    workflows.diamond.ac.uk/parameter-schema: |
      {{- .Files.Get "schema/mib2x_auto_Schema.json" | nindent 6 }}
    workflows.diamond.ac.uk/ui-schema: |
      {{- .Files.Get "schema/mib2x_auto_ui.json" | nindent 6 }}
spec:
  entrypoint: mib2x-auto
  arguments:
    parameters:
    - name: visitdir
      valueFrom:
        configMapKeyRef:
          name: sessionspaces
          key: data_directory
  ###
  volumes:
  - name: session
    hostPath:
      path:  "{{`{{ workflow.parameters.visitdir }}`}}"
      type: Directory
  volumeClaimTemplates:      # I think this is just defining resources be alloted to this task
  - metadata:
      name: tmpdir
    spec:
      accessModes: [ "ReadWriteOnce" ]  # I am guess this means only allowed one action?
      resources:
        requests:
          storage: 1Gi
      storageClassName: netapp
  ###
  templates:
    - name: mib2x-auto
      #inputs: 
      #  parameters: 


          #- name: #name parameters here
      steps: #steps is on the name level as inputs
      - - name: find
          template: find-mib-files
          #arguments:
            #parameters:
              #- name: base_path
              
      - - name: print-mib
          template: print-found-mib-files
          arguments:
            parameters:
              - name: mibfiles
                value: "{{`{{item}}`}}"
          withParam: "{{`{{steps.find.outputs.result}}`}}"
  ###
    - name: find-mib-files
      inputs:
        parameters:
        - name: sample_name
          value: "{{`{{workflow.parameters.sample_name}}`}}"
      outputs:
        artifacts:
        - name: find_files_logging
          path: /tmp/find_files_logging.txt
          archive:
            none: {}
      script:
        image: python:3.10
        volumeMounts:
          - name: session
            mountPath: "{{`{{ workflow.parameters.visitdir }}`}}"
          - name: tmpdir
            mountPath: /tmp
        command: [python]
        source: |
          #The aim of this code is to produce a "json list" such that withParams can the start parrelle
          #jobs based around this list, where each element of this list the uses on index of that list as 
          #input
          
          #imports
          import json
          import sys
          import os
          import glob 
          import traceback

          #creating temp varilbes to sort directory info
          mib_files = []
          converted_files = []
          mib_timestamps = []
          hdf5_timestamps = []
          data_to_convert = []
          logging = []
          #debugging print check
          verbose = True

          #start search for MIB files
          os.chdir('%s/Merlin/%s' % ("{{`{{workflow.parameters.visitdir}}`}}", "{{`{{ workflow.parameters.sample_name }}`}}"))

          source_path = os.getcwd() + '/'
          logging.append('Current path: %s' % source_path)

          #some simple example code to find the instances of mib files in a particular location

          logging.append('***\nSearching the following path: %s\n***' % source_path)
          for num, file in enumerate(sorted(list(glob.glob('*/**.mib*')))):
            if verbose:
              logging.append('%i: %s/%s' % (num, source_path, file))
            whole_file = os.path.join(source_path,file)
            mib_timestamps.append(whole_file.split('/')[-1][:-9])
            mib_files.append(whole_file)
          logging.append('total .mib files found: %i' % len(mib_files))
          mib_timestamps_set = set(mib_timestamps)
          
          
          dest_path = '/dls/e02/data/2025/%s/processing/Merlin/%s' % ("{{`{{workflow.parameters.visitdir}}`}}", "{{`{{inputs.parameters.sample_name}}`}}")

          if os.path.exists(dest_path):
            logging.append('\nThe following path exists: %s\nskipping creation of folder\n' %dest_path)
          else:
            logging.append('\nThe following path does not exists: %s\nTherefore creating this folder now...\n' %dest_path)
            os.mkdir(dest_path)

          os.chdir(dest_path)
          logging.append('***\nsearching destination path for already converted files: %s\n***' % dest_path)

          #ToDO wrap the rest of the function within this as means no other files have been created
          if not os.path.exists(dest_path):
            os.mkdir(dest_path)
            logging.append('the following folder has been created: %s' % dest_path)
          
          for num, file in enumerate(sorted(list(glob.glob('*/**data.hdf5*')))):
            converted_files.append(dest_path+file)
            hdf5_timestamps.append(converted_files[num].split('/')[-1][:-10])
            if verbose: 
              logging.append('%i: %s' % (num,converted_files[num]))       

          logging.append('Total converted files found: %i' % len(converted_files))

          timestamp_diff = list(mib_timestamps_set.difference(hdf5_timestamps))
          timestamp_diff.sort()
          logging.append('***\nA total of %i files have not be converted\n***' % len(list(timestamp_diff)))
          for num, ts in enumerate(timestamp_diff):
            mib_index = mib_timestamps.index(ts)
            logging.append('%i: %s' % (num, mib_files[mib_index]))
            data_to_convert.append(mib_files[mib_index])

          #ToDo think about this printing in the context of an Error
          #this should be try statement 
          with open("/tmp/find_files_logging.txt",'w') as ofile:
            for item in logging:
              print(item,file=ofile)

          #This is used to produce the input for the next step .i.e inputs.parameters.mibfiles
          json.dump(data_to_convert, sys.stdout)

    - name: print-found-mib-files
      inputs:
        parameters:
        - name: mibfiles
        - name: reshape_option
          value: "{{`{{ workflow.parameters.reshape_option }}`}}"
        - name: Scan_X
          value: "{{`{{ workflow.parameters.Scan_X}}`}}"
        - name: Scan_Y
          value: "{{`{{ workflow.parameters.Scan_Y }}`}}"
        - name: iBF
          value: "{{`{{ workflow.parameters.iBF }}`}}"
        - name: bin_sig_factor
          value: "{{`{{ workflow.parameters.bin_sig_factor }}`}}"
        - name: bin_nav_factor
          value: "{{`{{ workflow.parameters.bin_nav_factor }}`}}"
        - name: nprocs
          value: "{{`{{ workflow.parameters.nprocs }}`}}"
        - name: memory
          value: "{{`{{ workflow.parameters.memory }}`}}" 
        - name: DEBUG
          value: "{{`{{ workflow.parameters.DEBUG }}`}}" 
      script:
        image: ghcr.io/epsic-dls/mib2x:1.0.0
        imagePullPolicy: Always
        env:
        - name: BLOSC_NTHREADS
          value: "{{`{{ inputs.parameters.nprocs }}`}}"
        - name: OMP_NUM_THREADS
          value: "{{`{{ inputs.parameters.nprocs }}`}}"
        - name: M2X_DEBUG
          value: "{{`{{ inputs.parameters.DEBUG }}`}}"
        volumeMounts:
          - name: tmpdir    #session
            mountPath: /tmp
          - name: session
            mountPath: "{{`{{ workflow.parameters.visitdir }}`}}"
        command: [sh]
        source: |
          #!/bin/sh
          set -e

          cmd=("python" "mib_convert.py")
          cmd+=("--mib-path={{`{{inputs.parameters.mibfiles}}`}}")
          cmd+=("{{`{{inputs.parameters.reshape_option}}`}}")
          cmd+=("--scan-x={{`{{inputs.parameters.Scan_X}}`}}")
          cmd+=("--scan-y={{`{{inputs.parameters.Scan_Y}}`}}")
          if [ "{{`{{inputs.parameters.iBF}}`}}" = "true" ]
          then
            cmd+=("--ibf")
          fi
          cmd+=("--bin-sig-factor={{`{{ inputs.parameters.bin_sig_factor }}`}}")
          cmd+=("--bin-nav-factor={{`{{ inputs.parameters.bin_nav_factor }}`}}")

          # use exec to make application as PID 1 for signal handling
          echo "Executing: ${cmd[@]}"
          exec "${cmd[@]}"

      podSpecPatch: |
        containers:
        - name: main
          resources:
            requests:
              cpu: "{{`{{ inputs.parameters.nprocs }}`}}"
              memory: "{{`{{ inputs.parameters.memory }}`}}"
            limits:
              cpu: "{{`{{ inputs.parameters.nprocs }}`}}"
              memory: "{{`{{ inputs.parameters.memory }}`}}"
    




