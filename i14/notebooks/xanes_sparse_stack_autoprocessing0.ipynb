{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# outpath will be used to get outpath_nexus, outpath_mantis and outpath_complete for saving data, and outpath itself won't be used\n",
    "\n",
    "# default settings\n",
    "inpath = \"\" # type: str\n",
    "outpath = \"\" # type: str\n",
    "edge_element = \"\" # type: str\n",
    "sztol = 0.9 # type: float\n",
    "normalised = True  # type: bool\n",
    "completion_rank = 6 # type: int\n",
    "tol_residual = 1e-4 # type: float\n",
    "num_short_iteration = 75 # type: int\n",
    "num_final_iteration = 2000 # type: int\n",
    "auto_processing = True # type: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage \n",
    "\n",
    "This notebook takes the last scan file of a sparse XANES scan (`inpath`), defines the 2D full grid, inserts the data in the correct rows, stack the images, and completes the missing data by using looped alternating steepest descent (ASD). There are 3 output files:\n",
    "- the incomplete NeXuS file\n",
    "- the incomplete MANTIS file\n",
    "- the complete MATNIS file\n",
    "\n",
    "### Parameters\n",
    "`inpath` : str  \n",
    "the full path of the last scan file of a sparse XANES scan. e.g. \"/dls/i14/data/2024/cm37259-1/scan/i14-280251.nxs\"  \n",
    "`outpath` : str\n",
    "the full path of the output file. e.g. \"/dls/i14/data/2024/cm37259-1/processed/i14-280251_xanes_sparse_stack_autoprocessing0.nxs\". `outpath` will be overridden if it is triggered by auto-processing, as defined by the flag `auto_processing` (default to `True`); for post-processing, `outpath` will not be modified. `outpath` will then be used to make the file paths for 3 files: incomplete NeXuS file, incomplete MANTIS file and complete MANTIS file.  \n",
    "`edge_element` : str  \n",
    "the transition for the XRF window. e.g. \"Zr-Ka\"   \n",
    "`sztol` : float   \n",
    "The percentage tolerance of the size of the scan for declaring a scan to be removed or cropped.    \n",
    "The number must be between 0 and 1 and sensible value should be above 0.9.    \n",
    "The reference is always set by the scan first.    This applies to both x and y axis.      \n",
    "For example, if the size of x axis in first is 71 and sztol is 0.9:   \n",
    "dataset with x-axis size >63 (71\\*0.9 rounded down) will be cropped;   \n",
    "dataset with x-axis size <=63 will be removed from the stack.\n",
    "```\n",
    "<-0___________remove___________63-><-_____crop_____71->\n",
    "     |                                 |\n",
    "     |                                 |  \n",
    "     |     all the dataset will be cropped to the minimum x-axis size of the whole sequence\n",
    "     |     e.g. if one dataset has an x-axis size 67, all dataset is cropped to 67 in the x axis\n",
    "     |          it is not removed as it is higher than the tolerance\n",
    "     |\n",
    "     |\n",
    "     |\n",
    "all the dataset will be removed from the stack\n",
    "e.g. if a dataset has an x-axis size 21, it is removed\n",
    "     it is not cropped as it is lower than the tolerance\n",
    "```\n",
    "`completion_rank` : int   \n",
    "the maximum rank that the sparse XANES stack will be decomposed to for matrix completion. It should be between 3 to 12.   \n",
    "`tol_residual` : float   \n",
    "the iteration will stop once the residual is below this value.    \n",
    "`num_short_iteration` : int    \n",
    "the number of iteration for all but the final rank decomposition.   \n",
    "`num_final_iteration` : int   \n",
    "the number of iteration for the final rank decomposition.   \n",
    "`auto_processing` : bool    \n",
    "the flag to state this is an auto- or post-processing.    \n",
    "\n",
    "**The parameters should be provided by explicitly modifying the top cell content or using tools such as [papermill](https://papermill.readthedocs.io/en/latest/index.html). If the notebook is run as is, please define the parameters accordingly.**\n",
    "\n",
    "### Dependencies\n",
    "Majority of the work is carried out by [i14-utility-xanes](https://gitlab.diamond.ac.uk/i14/i14_utility).   \n",
    "- numpy\n",
    "- matplotlib\n",
    "- h5py\n",
    "- hyperspy\n",
    "- i14-utility (https://gitlab.diamond.ac.uk/i14/i14_utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import hyperspy.api as hs\n",
    "\n",
    "from i14_utility.xanes.window_xrf import (channel_start_end, read_raw_data, window_mca, check_inconsistent_axis, \n",
    "print_file_summary, full_x_axis, full_y_axis, sparse_y_indices, sparse_row_map, \n",
    "sparse_window_stack)\n",
    "from i14_utility.xanes.completion import LoopedASD, imagesc\n",
    "from i14_utility.xanes.io import save_mantis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "print(f\"HyperSpy version: {version('hyperspy')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get scan file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_file_dataset_path = \"/entry/previous_scan_files/paths\"\n",
    "\n",
    "if auto_processing:\n",
    "    try:\n",
    "        with h5py.File(inpath, \"r\") as f:\n",
    "            file_list = f[previous_file_dataset_path][()]\n",
    "    except FileNotFoundError as err:\n",
    "        msg = f\"The file {inpath} cannot be found, perhaps the year/visit is wrong?\"\n",
    "        raise FileNotFoundError(msg) from err\n",
    "    except KeyError as err:\n",
    "        msg = (f\"The dataset path {previous_file_dataset_path} seems not present, \" \n",
    "            f\"please check if {inpath} is the last scan of a sparse XANES experiment.\")\n",
    "        raise KeyError(msg) from err\n",
    "    else:\n",
    "        # add the current one\n",
    "        file_list = [f.decode() for f in file_list] + [inpath]\n",
    "\n",
    "print(f\"Number of scan files in the list: {len(file_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Line group to be aligned: {edge_element}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window here \n",
    "Instead of reading processed file to avoid endless trouble about data location/dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "windowed = []\n",
    "energy_data =[]\n",
    "SampleX = []\n",
    "SampleY = []\n",
    "scan_shapes = []\n",
    "I0_total = []\n",
    "\n",
    "lg_start, lg_end = channel_start_end(edge_element)\n",
    "\n",
    "for raw_data in file_list:\n",
    "    # windowing happens here for each file\n",
    "    data = read_raw_data(raw_data)\n",
    "    \n",
    "    # window it\n",
    "    w_mca = window_mca(data[\"mca\"], lg_start, lg_end, data[\"scan_shape\"], data[\"scan_model\"])\n",
    "  \n",
    "    # sum the I0\n",
    "    I0_t = np.squeeze(data[\"I0_1\"] + data[\"I0_2\"] + data[\"I0_3\"] + data[\"I0_4\"])\n",
    "    \n",
    "    # record everything\n",
    "    windowed.append(w_mca)\n",
    "    \n",
    "    energy_data.append(data[\"energy\"])\n",
    "    SampleX.append(data[\"x\"])\n",
    "    SampleY.append(data[\"y\"])\n",
    "    scan_shapes.append(data[\"scan_shape\"])\n",
    "    I0_total.append(I0_t)\n",
    "    \n",
    "print(f\"Time reading raw data: {(time.perf_counter() - start)/60:.2f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check inconsistency of element maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_scan_x, dim_x = check_inconsistent_axis(SampleX, scan_shapes, sztol=sztol)\n",
    "valid_scan_y, dim_y = check_inconsistent_axis(SampleY, scan_shapes, sztol=sztol)\n",
    "valid_scan = valid_scan_x & valid_scan_y\n",
    "dim_ = min(dim_x, dim_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A summary of scan files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first, last = print_file_summary(file_list, valid_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first scan shape in the file list\n",
    "print(f\"Original elemental map shape: {scan_shapes[0]}\")\n",
    "print(f\"Elemental map shape of the stack: ({dim_},)\")\n",
    "print(f\"Number of elemental maps in the stack: {np.count_nonzero(valid_scan)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Override paths of output files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = Path(outpath).parent / \"xanes_sparse\"\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"output_folder is {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_num = re.search(r\"^.*i14-(\\d+)\\.nxs$\", first).group(1)\n",
    "last_num = re.search(r\"^.*i14-(\\d+)\\.nxs$\", last).group(1)\n",
    "\n",
    "outpath_nexus = str(output_folder / f\"i14_{first_num}_{last_num}_stack.nxs\")\n",
    "outpath_mantis = str(output_folder / f\"i14_{first_num}_{last_num}_mantis.hdf5\")\n",
    "outpath_complete = str(output_folder / f\"i14_{first_num}_{last_num}_completion.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The NeXus file: {outpath_nexus}\")\n",
    "print(f\"The MANTIS (incomplete) file: {outpath_mantis}\")\n",
    "print(f\"The MANTIS (complete) file: {outpath_complete}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine overall scan size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xall = full_x_axis(SampleX)\n",
    "yall, y_coords = full_y_axis(SampleY, return_coords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_size, x_size = yall.size, xall.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine scan row and put into the scan stack\n",
    "The left figure should look quite random, the right figure should only show one value if each sparse scan contains equal number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanned_rows = sparse_y_indices(yall, y_coords)\n",
    "_ = sparse_row_map(scanned_rows, y_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = sparse_window_stack(windowed, scanned_rows, y_size, x_size, I0_total=I0_total, normalised=normalised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to a HyperSpy signal and save it as NeXus file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = hs.signals.Signal2D(stack, signal_axes=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig.axes_manager[1].offset = np.min(xall)\n",
    "sig.axes_manager[1].scale = abs(np.diff(xall).min())\n",
    "sig.axes_manager[1].name = \"X\"\n",
    "sig.axes_manager[1].units = \"mm\"\n",
    "\n",
    "sig.axes_manager[2].offset = np.min(yall)\n",
    "sig.axes_manager[2].scale = abs(np.diff(yall).min())\n",
    "sig.axes_manager[2].name = \"Y\"\n",
    "sig.axes_manager[2].units = \"mm\"\n",
    "\n",
    "sig.metadata.set_item(\"Acquisition_instrument.XRF.beam_energy\", np.asarray(energy_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving NeXus file at {outpath_nexus}\")\n",
    "sig.save(outpath_nexus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as MANTIS Exchange format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_white_spectrum = np.ones_like(energy_data)\n",
    "new_energy = np.asarray(energy_data) * 1000\n",
    "comment = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving MANTIS file (incomplete) at {outpath_mantis}\")\n",
    "\n",
    "save_mantis(outpath_mantis, stack.T,\n",
    "            ax_energy=new_energy,\n",
    "            ax_white=new_white_spectrum,\n",
    "            comment=comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix completion\n",
    "Using looped alternating steepest descent. (origianl codes by Oliver Townsend/Paul Quinn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_asd = LoopedASD(stack.T, \n",
    "                     rank_max=completion_rank, \n",
    "                     tol=tol_residual, \n",
    "                     niter_short=num_short_iteration, \n",
    "                     niter_final=num_final_iteration, \n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.perf_counter()\n",
    "\n",
    "loop_asd.start_looping()\n",
    "\n",
    "te = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Completion run time: {te-ts} s\")\n",
    "print(f\"True undersample ratio: {loop_asd.undersampling_ratio}\")\n",
    "print(f\"Completion Residual: {loop_asd.residuals[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesc(loop_asd.flatten, im_title='Sparse Data Color Map')\n",
    "imagesc(loop_asd.low_rank_matrix, im_title='Completed Data Color Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(np.log10(loop_asd.residuals))\n",
    "_ = ax.set_xlabel(\"Number of iterations\")\n",
    "_ = ax.set_ylabel(r\"$\\mathrm{log}_{10}$ R\")\n",
    "_ = ax.set_title(\"Log residual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = loop_asd.stack_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving MANTIS file (complete) at {outpath_complete}\")\n",
    "\n",
    "save_mantis(outpath_complete, data_complete,\n",
    "            ax_energy=new_energy,\n",
    "            ax_white=new_white_spectrum,\n",
    "            comment=comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
