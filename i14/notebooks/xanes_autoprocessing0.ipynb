{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# default settings\n",
    "inpath = \"\" # type: str\n",
    "outpath = \"\" # type: str\n",
    "edge_element = \"\" # type: str\n",
    "window_width = 40 # type: int\n",
    "sztol = 0.9  # type: float\n",
    "normalised = True  # type: bool\n",
    "method = \"mutual\"  # type: str\n",
    "ref_index = None  # type: int\n",
    "max_fractional_shift = 0.2  # type: float\n",
    "auto_processing = True # type: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking and alignment for XANES\n",
    "This notebook attempts to stack a sequence of datasets acquired at different energy for a particular line group and perform alignment based on a line group. Some functionalities like normalisation, cropping and removing inconsistent size of scanning axis are incoporated. The algorithm for alignment is by mutual information or phase correlation. The aligned stack is saved as an hdf5 file which can be recognised by Mantis for further analysis.\n",
    "\n",
    "## Parameters\n",
    "    \n",
    "**inpath** : string  \n",
    "    The last raw data file of the XANES stack, it must contain the `\"/entry/previous_scan_files/paths\"` entry.   \n",
    "    For example, `\"/dls/i14/data/2023/cm33895-3/scan/i14-234367.nxs\"`. \n",
    "\n",
    "**outpath** : string  \n",
    "    The output file of the XANES stack, which is compatible to Mantis.       \n",
    "    For example, `\"/dls/i14/data/2023/cm33895-3/processed/mantis_xanes_234367.hdf5\"`.   \n",
    "    \n",
    "**edge_element** : string  \n",
    "    The line group of interested. This can be the same as _element_to_align_ or different.  \n",
    "    For example, `\"Ca-Ka\"` or `\"Fe-Ka\"`.   \n",
    "    \n",
    "**window_width** : int  \n",
    "    The channel width for the XRF window.  \n",
    "    For example, `40`.  \n",
    "    \n",
    "**sztol** : float   \n",
    "    The percentage tolerance of the size of the scan for declaring a scan to be removed or cropped.    \n",
    "    The number must be between 0 and 1 and sensible value should be above 0.9.    \n",
    "    The reference is always set by the scan _first_.    \n",
    "    This applies to both x and y axis.   \n",
    "       \n",
    "       \n",
    "   For example, if the size of x axis in _first_ is 71 and _sztol_ is 0.9:   \n",
    "   dataset with x-axis size >63 (71\\*0.9 rounded down) will be cropped;   \n",
    "   dataset with x-axis size <=63 will be removed from the stack.\n",
    "    \n",
    "    <-0___________remove___________63-><-_____crop_____71->\n",
    "         |                                 |\n",
    "         |                                 |  \n",
    "         |     all the dataset will be cropped to the minimum x-axis size of the whole sequence\n",
    "         |     e.g. if one dataset has an x-axis size 67, all dataset is cropped to 67 in the x axis\n",
    "         |          it is not removed as it is higher than the tolerance\n",
    "         |\n",
    "         |\n",
    "         |\n",
    "    all the dataset will be removed from the stack\n",
    "    e.g. if a dataset has an x-axis size 21, it is removed\n",
    "         it is not cropped as it is lower than the tolerance\n",
    "       \n",
    "**normalised** : boolean    \n",
    "    Whether to normalise the stack by I0.\n",
    "    `True` or `False`.\n",
    "    \n",
    "**method** : string   \n",
    "    The method to use for alignment. `mutual` (mutual information) or `fourier` (Fourier correlation).\n",
    "    \n",
    "**ref_index** : None or integer   \n",
    "    The index of the reference image for alignment.  \n",
    "    If `None`, the reference image is the one with maximum total intensity. This works most of the time.\n",
    "    \n",
    "**max_fractional_shift** : float   \n",
    "    <span style=\"color:blue\">This is only relevant when _method_ is \"mutual\".</span>   \n",
    "    This number is used to define the maximum shift that could be applied to an axis, as a fraction of the size of the axis.  \n",
    "    This should be between 0 and 1. Setting it to a higher number results in longer duration of alignment.   \n",
    "    A sensible value is between `0.2` and `0.4`.\n",
    "\n",
    "**auto_processing** : bool    \n",
    "    the flag to state this is an auto- or post-processing.    \n",
    "\n",
    "         \n",
    "## Legacy workflow\n",
    "1. There is no need to have the variable _element_to_load_ as this is redundant; it is determined from _element_to_align_ and _edge_element_.\n",
    "2. There is no need to specify (although you can do this through _to_remove_) the problematic scan number that is to be removed from the stack. It is done via the tolerance _sz_tol_, and the cropping and removal are all done via this. \n",
    "3. The algorithm for alignment is changed from Fourier correlation (in-built in HyperSpy) to mutual information (written by Paul Q). This is believed to be more robust.\n",
    "\n",
    "## Working environment\n",
    "This notebook is developed under the `python/epsic3.10` environment (available after `module load python/epsic3.10`). It works both locally and in cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hyperspy.api as hs\n",
    "\n",
    "from i14_utility.xanes.mutual import estimate_shift2D_mutual\n",
    "from i14_utility.xanes.window_xrf import (channel_start_end, read_raw_data, window_mca, check_inconsistent_xy, \n",
    "crop_stack_map, print_file_summary)\n",
    "from i14_utility.xanes.io import save_mantis, save_stack_as_gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "print(f\"HyperSpy version: {version('hyperspy')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Override the outpath\n",
    "Save the file with `.hdf5` extension and inside `.../processed/xanes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = Path(outpath)\n",
    "processed_xanes = op.parent / \"xanes\"\n",
    "processed_xanes.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "processed_xanes_nxs = processed_xanes / op.name\n",
    "\n",
    "mantis_outpath = str(processed_xanes_nxs.with_suffix(\".hdf5\"))\n",
    "gif_outpath = str(processed_xanes_nxs.with_suffix(\".gif\"))\n",
    "png_outpath = str(processed_xanes_nxs.with_suffix(\".png\")) \n",
    "\n",
    "print(f\"The MANTIS file will be saved as {mantis_outpath}\")\n",
    "print(f\"The GIF file will be saved as {gif_outpath}\")\n",
    "print(f\"The PNG file will be saved as {png_outpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the list of scans and tracking line from the last file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if auto_processing:\n",
    "    try:\n",
    "        with h5py.File(inpath, \"r\") as f:\n",
    "            file_list = f[\"/entry/previous_scan_files/paths\"][()]\n",
    "            element_to_align = f[\"/entry/line\"][()].decode()\n",
    "    except:\n",
    "        raise\n",
    "    else:\n",
    "        file_list = [f.decode() for f in file_list] + [inpath]\n",
    "        print(f\"Number of scan files in the list: {len(file_list)}\")\n",
    "else:\n",
    "    exclude = ast.literal_eval(exclude)\n",
    "    file_list = [f\"{visit_dir}/scan/i14-{x}.nxs\" for x in range(first, last + 1) if x not in exclude]\n",
    "        \n",
    "if not element_to_align or element_to_align == \"None\":\n",
    "    element_to_align = edge_element\n",
    "    \n",
    "print(f\"Number of scan files in the list: {len(file_list)}\")\n",
    "print(f'Line group used for tracking: {element_to_align}')\n",
    "print(f'Line group to be aligned: {edge_element}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window both element_to_align and edge_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "stack_element_align = []\n",
    "stack_edge_element = []\n",
    "energy_data = []\n",
    "SampleX = []\n",
    "SampleY = []\n",
    "scan_shapes = []\n",
    "I0_total = []\n",
    "\n",
    "start_align, end_align = channel_start_end(element_to_align, width=window_width)\n",
    "start_edge, end_edge = channel_start_end(edge_element, width=window_width)\n",
    "\n",
    "for raw_data in file_list:\n",
    "    # windowing happens here for each file\n",
    "    data = read_raw_data(raw_data)\n",
    "    \n",
    "    # window it\n",
    "    windowed_align = window_mca(data[\"mca\"], start_align, end_align, data[\"scan_shape\"], data[\"scan_model\"])\n",
    "    if edge_element != element_to_align:\n",
    "        windowed_edge = window_mca(data[\"mca\"], start_edge, end_edge, data[\"scan_shape\"], data[\"scan_model\"])\n",
    "    else:\n",
    "        windowed_edge = windowed_align\n",
    "    \n",
    "    # sum the I0\n",
    "    I0_t = np.squeeze(data[\"I0_1\"] + data[\"I0_2\"] + data[\"I0_3\"] + data[\"I0_4\"])\n",
    "    \n",
    "    # record everything\n",
    "    stack_element_align.append(windowed_align)\n",
    "    stack_edge_element.append(windowed_edge)\n",
    "    \n",
    "    energy_data.append(data[\"energy\"])\n",
    "    SampleX.append(data[\"x\"])\n",
    "    SampleY.append(data[\"y\"])\n",
    "    scan_shapes.append(data[\"scan_shape\"])\n",
    "    I0_total.append(I0_t)\n",
    "    \n",
    "print(f\"Time reading raw data: {(time.perf_counter() - start)/60:.2f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check inconsistency of element maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_scan, dim_x, dim_y = check_inconsistent_xy(SampleX, SampleY, scan_shapes, sztol=sztol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A summary of scan files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first, last = print_file_summary(file_list, valid_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first scan shape in the file list\n",
    "print(f\"Original elemental map shape in (y, x): {scan_shapes[0]}\")\n",
    "print(f\"Elemental map shape of the stack in (y, x): ({dim_y}, {dim_x})\")\n",
    "print(f\"Number of elemental maps in the stack: {np.count_nonzero(valid_scan)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the stack as HyperSpy signal\n",
    "This is for easier inspection and interface with alignment function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.asarray(SampleX)[valid_scan][0]\n",
    "y_axis = np.asarray(SampleY)[valid_scan][0]\n",
    "energy_data = np.asarray(energy_data)[valid_scan]\n",
    "\n",
    "xax_dict = {\"offset\": x_axis[0], \"scale\": x_axis[1]-x_axis[0], \"size\": x_axis.size, \"units\": \"mm\"}\n",
    "yax_dict = {\"offset\": y_axis[0], \"scale\": y_axis[1]-y_axis[0], \"size\": y_axis.size, \"units\": \"mm\"}\n",
    "\n",
    "ndata = np.asarray(file_list)[valid_scan].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = crop_stack_map(stack_element_align, valid_scan, dim_x, dim_y)\n",
    "s_element_align = hs.signals.Signal2D(tmp, axes=[{\"size\": tmp.shape[0]}, xax_dict, yax_dict])\n",
    "\n",
    "tmp = crop_stack_map(stack_edge_element, valid_scan, dim_x, dim_y)\n",
    "s_edge_element = hs.signals.Signal2D(tmp, axes=[{\"size\": tmp.shape[0]}, xax_dict, yax_dict])\n",
    "\n",
    "tmp = crop_stack_map(I0_total, valid_scan, dim_x, dim_y)\n",
    "s_i0_total = hs.signals.Signal2D(tmp, axes=[{\"size\": tmp.shape[0]}, xax_dict, yax_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the element_to_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ref_index is None:\n",
    "    ref_index = np.argmax(s_element_align.sum(axis=(1,2))).data[0]\n",
    "\n",
    "if not 0 <= ref_index <= ndata-1:\n",
    "    raise ValueError(f\"The reference index {ref_index} for alignment is out of bound, should be between 0 and {ndata-1}\")\n",
    "\n",
    "s_element_align.axes_manager[0].index = ref_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The image shown here is the one used as the reference for alignment.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_element_align.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align element_to_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (method := method.lower()) == \"mutual\":\n",
    "    # mutual information\n",
    "    print(\"Using mutual information\")\n",
    "    shifts, max_vals = estimate_shift2D_mutual(s_element_align,\n",
    "                                               reference=\"current\",\n",
    "                                               bin_rule=\"sturges\",\n",
    "                                               max_fractional_shift=max_fractional_shift,\n",
    "                                               brute=False\n",
    "                                              )\n",
    "    s_element_align.align2D(shifts=shifts)\n",
    "elif method == \"fourier\":\n",
    "    # fourier correlation\n",
    "    print(\"Using Fourier correlation\")\n",
    "    shifts = s_element_align.align2D(reference=\"current\",\n",
    "                                     normalize_corr=True,\n",
    "                                    )\n",
    "\n",
    "else:\n",
    "    raise ValueError(f'Method \"{method}\" not recognised, either \"mutual\" or \"fourier\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the shifts for element_to_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(shifts[:, 0])\n",
    "ax[0].set_title(\"Row shifts\")\n",
    "ax[1].plot(shifts[:, 1])\n",
    "ax[1].set_title(\"Column shifts\")\n",
    "\n",
    "print(f\"Sum of all row shifts: {np.sum(shifts[:, 0])}\")\n",
    "print(f\"Sum of all column shifts: {np.sum(shifts[:, 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align I0 sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalised:\n",
    "    s_i0_total.align2D(shifts=shifts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align the edge_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_edge_element.align2D(shifts=shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_edge_element.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the I0 sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalised:\n",
    "    s_i0_total.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise the stack by I0 sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalised:\n",
    "    i0_max = s_i0_total.data.max()\n",
    "    stack_norm_reduced = s_edge_element / (s_i0_total / i0_max)\n",
    "else:\n",
    "    stack_norm_reduced = s_edge_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot energy of the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(energy_data, \"C0.-\")\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_ylabel(\"energy (keV)\")\n",
    "ax.set_title(\"Energy of the stack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_white_spectrum = np.ones_like(energy_data)\n",
    "new_energy = np.asarray(energy_data) * 1000\n",
    "comment = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mantis(mantis_outpath, stack_norm_reduced.data.T,\n",
    "            ax_energy=new_energy,\n",
    "            ax_white=new_white_spectrum,\n",
    "            comment=comment,\n",
    "            shifts=shifts,\n",
    "           )\n",
    "print(f\"File written: {mantis_outpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save edge_element image stack as a gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = save_stack_as_gif(stack_norm_reduced.data, gif_outpath)\n",
    "\n",
    "print(f\"Saving edge_element image stack gif to {gif_outpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save edge_element integral intensity plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_integral = stack_norm_reduced.data.sum((-2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving edge_element integral intensity to {png_outpath}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(energy_data, edge_integral, \"r-\")\n",
    "ax.set_title(edge_element)\n",
    "ax.set_xlabel(\"energy (keV)\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(png_outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
